{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6fc01f-2780-4551-9de7-e9c8e1de5e3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.full as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.widgets as sw\n",
    "import probeinterface as pi\n",
    "from probeinterface import Probe, ProbeGroup\n",
    "from probeinterface.plotting import plot_probe, plot_probe_group\n",
    "from probeinterface import generate_multi_columns_probe\n",
    "import pyintan\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "from pathlib import Path\n",
    "import random \n",
    "import pandas as pd\n",
    "import mountainsort5 as ms5\n",
    "all_rec_lists = []\n",
    "all_names = []\n",
    "all_chan = []\n",
    "all_type = []\n",
    "\n",
    "main_folder = Path(\"E:\\Animal_recordings_all\\depth_4ch\\LKO_depth_4ch\\LKO_Chronic\\LKO_Chronic_2\")\n",
    "subfolders = [f.path for f in os.scandir(main_folder) if f.is_dir()]\n",
    "\n",
    "hours_needed = 20\n",
    "minutes_per_hour = 60\n",
    "total_minutes_needed = hours_needed * minutes_per_hour\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    print(f\"\\nContents of {subfolder}:\")\n",
    "    \n",
    "    list_of_files = os.listdir(subfolder)\n",
    "    list_of_files = [file for file in list_of_files if 'merged' not in file]\n",
    "    list_of_files = [file for file in list_of_files if 'settings' not in file]\n",
    "    error_files = []\n",
    "    print(len(list_of_files))\n",
    "    \n",
    "    total_minutes_collected = 0\n",
    "    subfolder_rec_list = []\n",
    "\n",
    "    while total_minutes_collected < total_minutes_needed and len(list_of_files) > 0:\n",
    "        remaining_minutes_needed = total_minutes_needed - total_minutes_collected\n",
    "        list_of_files_subset = list_of_files[:min(remaining_minutes_needed, 60)]\n",
    "        \n",
    "        print(f\"Processing these files: {list_of_files_subset}\")\n",
    "        \n",
    "        list_of_recordings = []\n",
    "        for file_name in list_of_files_subset:\n",
    "            file_path = os.path.join(subfolder, file_name)\n",
    "            try:\n",
    "                recording = se.read_intan(file_path, stream_name='RHD2000 amplifier channel', use_names_as_ids=True)  # Assuming data is float32\n",
    "                list_of_recordings.append(recording)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_name}: {e}\")\n",
    "                error_files.append(file_name)\n",
    "                continue\n",
    "\n",
    "        if len(list_of_recordings) > 0:\n",
    "            try:\n",
    "                concatenated_recording = si.concatenate_recordings(list_of_recordings)\n",
    "                rec_cmr = spre.common_reference(concatenated_recording, operator=\"median\", reference=\"global\")  # Rereferencing the data\n",
    "                recording_notch_ecog = spre.notch_filter(rec_cmr, q=50)  # Notch filter\n",
    "                recording_bp = spre.bandpass_filter(recording_notch_ecog, freq_min=300, freq_max=6000)  # Bandpass filter\n",
    "                recording_resampled_ecog = recording_bp\n",
    "\n",
    "                subfolder_rec_list.append(recording_resampled_ecog)\n",
    "                \n",
    "                channel_ids = recording_resampled_ecog.get_channel_ids()\n",
    "                fs = recording_resampled_ecog.get_sampling_frequency()\n",
    "                num_chan = recording_resampled_ecog.get_num_channels()\n",
    "                num_segments = recording_resampled_ecog.get_num_segments()\n",
    "                \n",
    "                print(\"Channel_ids =\", channel_ids)\n",
    "                print(f\"Sampling_frequency = {fs}\")\n",
    "                print(\"Number of Channels =\", num_chan)\n",
    "                print(\"Number of segments =\", num_segments)\n",
    "                print('Total_rec_duration =', recording_resampled_ecog.get_total_duration())\n",
    "\n",
    "                k = subfolder.split(\"/\")[-1]\n",
    "                name = k.split(\"\\\\\")[-1]\n",
    "\n",
    "                \n",
    "                all_chan.append(num_chan)\n",
    "\n",
    "                if re.search(r'lko|LKO|L', name):\n",
    "                    type = 'LKO'\n",
    "                    print(f\"Type: {type}\")\n",
    "                else:\n",
    "                    type = 'WT'\n",
    "                    print(\"Type: Not matched\")\n",
    "                \n",
    "                all_type.append(type)\n",
    "                \n",
    "                total_minutes_collected += len(list_of_recordings)\n",
    "\n",
    "            except ValueError as ve:\n",
    "                print(f\"Concatenation error in folder {subfolder}: {ve}\")\n",
    "                continue\n",
    "\n",
    "        list_of_files = list_of_files[len(list_of_files_subset):]\n",
    "    all_names.append(name)\n",
    "    if total_minutes_collected >= total_minutes_needed:\n",
    "        print(f\"Successfully created {hours_needed} hours of recordings.\")\n",
    "    else:\n",
    "        print(f\"Collected {total_minutes_collected} minutes of recordings.\")\n",
    "    \n",
    "    # Add the subfolder's recordings list to the main list\n",
    "    all_rec_lists.append(subfolder_rec_list)\n",
    "\n",
    "print(f\"Error files: {error_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641b99f-f960-48b6-b397-b236d05f47da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hour = ['first_60', 'second_60', 'third_60', 'fourth_60', 'fifth_60', 'sixth_60', 'seventh_60', 'eighth_60', 'ninth_60', 'tenth_60', 'eleventh_60', 'twelfth_60', 'thirteenth_60', 'fourteenth_60', 'fifteenth_60', 'sixteenth_60', 'seventeenth_60', 'eighteenth_60', 'nineteenth_60', 'twentieth_60']\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "g = 1\n",
    "all_sorting=[]\n",
    "for i in range(len(all_rec_lists)):\n",
    "     for j in range(len(all_rec_lists[i])):\n",
    "        print(i,j)\n",
    "        ch = all_rec_lists[i][j].get_num_channels()\n",
    "        print(i, j)\n",
    "        if ch >= 4:\n",
    "            sliced_ch = all_rec_lists[i][j].get_channel_ids()\n",
    "            sliced_ch = sliced_ch[:4]\n",
    "            #sliced_ch = sliced_ch[4:9]\n",
    "            all_rec_lists[i][j] = all_rec_lists[i][j].channel_slice(sliced_ch)\n",
    "            \n",
    "            #if ch == 4:\n",
    "            ch = all_rec_lists[i][j].get_num_channels()\n",
    "            dur = all_rec_lists[i][j].get_total_duration()\n",
    "            \n",
    "           \n",
    "            kk = all_rec_lists[i][j]\n",
    "            #kk = se.read_intan(kk, stream_name='RHD2000 amplifier channel', use_names_as_ids=True)\n",
    "            recording_resampled_ecog = kk\n",
    "           \n",
    "            probe = generate_multi_columns_probe(num_columns=3,\n",
    "                             num_contact_per_column=[1, 2, 1],\n",
    "                             xpitch=75, ypitch=155, y_shift_per_column=[0, -75, 0],\n",
    "                             contact_shapes='square', contact_shape_params={'width' : 20 , 'height' :20 })\n",
    "\n",
    "            channel_indices = np.array([0, 1, 3, 2])\n",
    "            probe.set_device_channel_indices(channel_indices)\n",
    "            print(probe.device_channel_indices)\n",
    "            \n",
    "            contact_ids = np.array([0, 1, 3, 2]) \n",
    "            probe.set_contact_ids(contact_ids)\n",
    "            \n",
    "            rec_2.set_probe(probe, in_place = True)\n",
    "            rec_2.get_channel_locations()\n",
    "            plot_probe(probe, with_contact_id=True, with_device_index=True)\n",
    "                    \n",
    "            \n",
    "            rec_normed = spre.zscore(recording=recording_resampled_ecog)\n",
    "            rec_2 = spre.whiten(rec_normed) \n",
    "            \n",
    "                  \n",
    "            sorting_rec = ms5.sorting_scheme2(rec_2,\n",
    "                sorting_parameters=ms5.Scheme2SortingParameters(\n",
    "                    phase1_detect_channel_radius=150,\n",
    "                    detect_channel_radius=50))        \n",
    "            \n",
    "            all_sorting.append(sorting_rec)\n",
    "            \n",
    "            print(\"Sorter found\", len(sorting_rec.get_unit_ids()), \"units\")\n",
    "            sorting_rec = sorting_rec.remove_empty_units()\n",
    "            print(\"Sorter found\", len(sorting_rec.get_unit_ids()), \"non empty units\")\n",
    "            \n",
    "            recording_resampled_ecog.annotate(is_filtered=True) # since we filtered the rec \n",
    "    \n",
    "            if len(sorting_rec.get_unit_ids()) >0 :\n",
    "                print(\"non-zero-clusters\")\n",
    "                \n",
    "                print(f\"Processing: {name}, Type: {type}, Recording Index: {j}\")\n",
    "\n",
    "                waveform_folder = Path(r\"/home/ayandas22/Animal_recordings_all/LKO_depth_4ch/LKO_Chronic/LKO_Chronic_2\")\n",
    "                waveform_folder = waveform_folder / f\"waveforms_kshtj_{all_names[i]}_{hour[j]}\" \n",
    "            \n",
    "                waveform_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                type = all_type[i]  \n",
    "                print(f\"Processing {name} at index {i}\")\n",
    "\n",
    "                we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False) \n",
    "                spost.compute_spike_amplitudes(we)\n",
    "            \n",
    "                unit_ids = sorting_rec.unit_ids\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                sw.plot_unit_templates(we, unit_ids=unit_ids)\n",
    "                plt.suptitle(f\"{all_names[i]}_{hour[j]}\", fontsize=12, y=0.01)\n",
    "                plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "                plots_directory =  Path(r\"/home/ayandas22/Animal_recordings_all/LKO_depth_4ch/LKO_Chronic/LKO_Chronic_2\")\n",
    "                plots_directory.mkdir(parents=True, exist_ok=True) \n",
    "                plt.savefig(plots_directory / f\"{all_names[i]}_{hour[j]}_xx.png\", bbox_inches='tight')\n",
    "               \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4785fdb-78dc-448b-93a0-611851c031a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Type: LKO\n",
      "205\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "36\n",
      "Type: LKO\n",
      "1\n",
      "Type: LKO\n",
      "8\n",
      "Type: LKO\n",
      "35\n",
      "Error reading file chronic_2nd_lko_day_18march_240318_174849.rhs: Size of available data is not a multiple of the data-type size.\n",
      "Type: LKO\n",
      "835\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "74\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "7\n",
      "Type: LKO\n",
      "1\n",
      "Type: LKO\n",
      "262\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "13\n",
      "Type: LKO\n",
      "1\n",
      "Type: LKO\n",
      "536\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Type: LKO\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_210831.rhs: 'utf-16-le' codec can't decode bytes in position 372-373: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_210931.rhs: 'utf-16-le' codec can't decode bytes in position 5738-5739: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_211031.rhs: 'utf-16-le' codec can't decode bytes in position 196-197: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_211131.rhs: 'utf-16-le' codec can't decode bytes in position 34-35: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_211231.rhs: 'utf-16-le' codec can't decode bytes in position 262-263: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_211331.rhs: 'utf-16-le' codec can't decode bytes in position 66-67: illegal UTF-16 surrogate\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_211431.rhs: 'utf-16-le' codec can't decode bytes in position 178-179: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_211531.rhs: 'utf-16-le' codec can't decode bytes in position 584-585: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_211631.rhs: 'utf-16-le' codec can't decode bytes in position 2684-2685: illegal UTF-16 surrogate\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_211731.rhs: 'utf-16-le' codec can't decode bytes in position 240-241: illegal UTF-16 surrogate\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_211831.rhs: 'utf-16-le' codec can't decode bytes in position 3508-3509: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_211931.rhs: 'utf-16-le' codec can't decode bytes in position 4964-4965: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_212031.rhs: 'utf-16-le' codec can't decode bytes in position 1376-1377: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_212131.rhs: 'utf-16-le' codec can't decode bytes in position 1374-1375: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_212231.rhs: 'utf-16-le' codec can't decode bytes in position 6634-6635: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_212331.rhs: 'utf-16-le' codec can't decode bytes in position 34-35: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_212431.rhs: 'utf-16-le' codec can't decode bytes in position 972-973: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_212531.rhs: 'utf-16-le' codec can't decode bytes in position 5924-5925: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_212631.rhs: 'utf-16-le' codec can't decode bytes in position 934-935: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_212731.rhs: 'utf-16-le' codec can't decode bytes in position 9198-9199: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_212831.rhs: 'utf-16-le' codec can't decode bytes in position 7996-7997: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_212931.rhs: 'utf-16-le' codec can't decode bytes in position 188-189: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_213031.rhs: 'utf-16-le' codec can't decode bytes in position 182-183: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_213131.rhs: 'utf-16-le' codec can't decode bytes in position 522-523: illegal UTF-16 surrogate\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_213231.rhs: 'utf-16-le' codec can't decode bytes in position 800-801: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_213331.rhs: 'utf-16-le' codec can't decode bytes in position 80-81: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_213431.rhs: 'utf-16-le' codec can't decode bytes in position 242-243: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_213531.rhs: index 0 is out of bounds for axis 0 with size 0\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_213631.rhs: index 0 is out of bounds for axis 0 with size 0\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_213731.rhs: index 0 is out of bounds for axis 0 with size 0\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_213831.rhs: index 0 is out of bounds for axis 0 with size 0\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_213931.rhs: index 0 is out of bounds for axis 0 with size 0\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_214031.rhs: index 0 is out of bounds for axis 0 with size 0\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_214131.rhs: 'utf-16-le' codec can't decode bytes in position 19177100-19177101: illegal encoding\n",
      "Error reading file chronic_2nd_lko_day5_13march_2024_240313_214231.rhs: index 0 is out of bounds for axis 0 with size 0\n",
      "Type: LKO\n",
      "0\n",
      "0\n",
      "Error files: []\n",
      "0 0\n",
      "0 0\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 36.41173333333333 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 1092352\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 0.949 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 142 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 0.030 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.000 seconds ***\n",
      "Extracting 142 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.000 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.070 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 1 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.010 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.000 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [0]\n",
      "*** MS5 Elapsed time for align_templates: 0.000 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.000 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.011 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.000 seconds ***\n",
      "Found 1 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.000 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [0]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.000 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.000 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 1.086 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.000 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 0.281 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.008 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.050 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 1\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 0.261 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 236 spikes in chunk 1 of 1\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.020 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.020 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.000 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 0\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6795619934465e8841f4a367b8944e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ed56c5982d4bec9f85d6168b85cdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "1 0\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 3600.128 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 108003840\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 110.118 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 84070 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 3.080 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.009 seconds ***\n",
      "Extracting 81226 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.081 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.060 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 3 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 1.908 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.238 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [-10  -2   0]\n",
      "*** MS5 Elapsed time for align_templates: 0.005 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.050 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.040 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 1.857 seconds ***\n",
      "Found 4 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.222 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [-10   0 -10  -2]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.001 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.001 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.006 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 117.749 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.000 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 26.548 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.000 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.046 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.469 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 62426 spikes in chunk 1 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.881 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.503 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.030 seconds ***\n",
      "Time chunk 2 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.613 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 16178 spikes in chunk 2 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.447 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.151 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.010 seconds ***\n",
      "Time chunk 3 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.592 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 21193 spikes in chunk 3 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.458 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.211 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.007 seconds ***\n",
      "Time chunk 4 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 7.355 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 15789 spikes in chunk 4 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.511 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.131 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.010 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.010 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 0\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8679ce33da44092a36d677c8d24df1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700500460b7645f6962e27ce876c51e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "1 1\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 3600.128 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 108003840\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 105.654 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 27464 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 1.601 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.009 seconds ***\n",
      "Extracting 27446 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.025 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.023 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 3 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.453 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.059 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [ 6  0 -6]\n",
      "*** MS5 Elapsed time for align_templates: 0.000 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.019 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.030 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.278 seconds ***\n",
      "Found 2 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.071 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [-6  0]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.010 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.000 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 108.302 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.010 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 26.390 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.010 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.031 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 6.165 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 11427 spikes in chunk 1 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.389 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.075 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.011 seconds ***\n",
      "Time chunk 2 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 6.034 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 4817 spikes in chunk 2 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.272 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.030 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.010 seconds ***\n",
      "Time chunk 3 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 6.207 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 5568 spikes in chunk 3 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.310 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.048 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.003 seconds ***\n",
      "Time chunk 4 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 8.045 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 10696 spikes in chunk 4 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.489 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.072 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.000 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 1\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d27bb0c24b4a34b43d53c5226402ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a07d224e4c41939b82adc9da470c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "1 2\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 3600.128 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 108003840\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 105.928 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 15508 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 2.046 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.000 seconds ***\n",
      "Extracting 15284 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.010 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.030 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 2 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.296 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.030 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [-16   0]\n",
      "*** MS5 Elapsed time for align_templates: 0.010 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.010 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.021 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.170 seconds ***\n",
      "Found 1 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.045 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [-16]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.000 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.001 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 108.661 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.000 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 24.996 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.010 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.031 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.793 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 12242 spikes in chunk 1 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.497 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.131 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.011 seconds ***\n",
      "Time chunk 2 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.546 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 682 spikes in chunk 2 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.251 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.001 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 3 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.623 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 7463 spikes in chunk 3 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.513 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.061 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 4 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 7.346 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 2929 spikes in chunk 4 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.367 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.040 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.000 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 2\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4763e72dd8f740eab47a753a0aee6d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb7e7fc5fe74069963077784a342496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3\n",
      "1 3\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 5052.3008 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 151569024\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 152.462 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 8227 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 3.536 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.000 seconds ***\n",
      "Extracting 7960 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.013 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.020 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 183 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 30.079 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.032 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [ 7  1  1 -2  1  3  1  2  6  2  1  6  6  3  2  2  2  4  5  2  1  3  3  1\n",
      "  1  1  3  3  7  2  6  0  3  3  4  3  6  1  1  3  6  6  6  4  1  4  7  4\n",
      "  0  3 -5  3  1 -2  0  1  5  2  1  3  2  4 -1  3  4  6  6  3  3  1  4  0\n",
      "  2  2 -6 -5 -6 -7  4  2 -1  1  4  0  3  2  2  0  0  0  0  0  1  0  4  8\n",
      "  1  0  4  5  4  3 -1  0  1  7  4  4  8  6  0  1  0  9  8  7  6  6  6  5\n",
      "  5  5  6  4  6  7  2  1  8  4  1  0 -1  4  2 -1 -1 -2  0  0  0  1  8  2\n",
      " -1  6 -2  0  0  0 -1  8 -1 -1  7 -2  2  7  0  0  1  1  1  0  0  1  1  1\n",
      "  1  0  0  0  0  1  1  0  1  1  4  0  1  8  1]\n",
      "*** MS5 Elapsed time for align_templates: 15.351 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.010 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.020 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\.conda\\envs\\spike\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:652: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 24.301 seconds ***\n",
      "Found 189 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.040 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [ 0  3  2  3  3  2  3  1  3  2  1  1  4  3  2  2  2  2 -2  0  2  2  4  2\n",
      " -1  5  2  3  5  0  2  2  4  4 -4 -1  3  4  3  5  5  6  6  6  6  6  6  6\n",
      "  2  5  3  1  5  4 -6  2  4  5  3  3 -1  0  1  1  6  3  4  3  1  3  4 -7\n",
      " -6 -6 -6 -6  5  3  1  3  3  4  1  1  0  1  3  2  2  5  2  1  4 -1  5  2\n",
      " 13  2 -6  2  3  1  1  2  1  2  0  3  1 -2  0  6  6  0  1  3  1  3  0  1\n",
      "  4  6  1  0  1  1  4  7  7  6  6  5  5  5 16 11  6  6 10 12  5  7 12  5\n",
      " 12  5 12 10  6  6  4  3  5  3  1  1  1  0  4  0  4  2 -1  2  4  0 -1 -9\n",
      " -8  4  2  4  3 11  1  1  1  1  1  1  1  0  1  0  1  0  8  1  7]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.000 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.010 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.000 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 225.987 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.002 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 36.425 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.000 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.091 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 6\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.919 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 5834 spikes in chunk 1 of 6\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.558 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.139 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.010 seconds ***\n",
      "Time chunk 2 of 6\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.698 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 9927 spikes in chunk 2 of 6\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.720 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.250 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 3 of 6\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.843 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 222 spikes in chunk 3 of 6\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.265 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.007 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 4 of 6\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.698 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 3893 spikes in chunk 4 of 6\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.400 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.124 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.002 seconds ***\n",
      "Time chunk 5 of 6\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.924 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 199 spikes in chunk 5 of 6\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.246 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.006 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.001 seconds ***\n",
      "Time chunk 6 of 6\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 6.142 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 5829 spikes in chunk 6 of 6\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.572 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.162 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.010 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 3\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0a2b7b89fb4124a1628c1e40d1f458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/5053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45e2511d1094d4aaa9a6cd5ff1823d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/5053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "2 0\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 2136.4992 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 64094976\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 62.395 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 32434 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 3.917 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.000 seconds ***\n",
      "Extracting 32345 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.031 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.020 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 3 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.845 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.070 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [ 0 19  0]\n",
      "*** MS5 Elapsed time for align_templates: 0.000 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.024 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.026 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.755 seconds ***\n",
      "Found 3 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.070 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [ 0 19  0]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.000 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.000 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 68.204 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.000 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 14.437 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.010 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.050 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 3\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.550 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 14931 spikes in chunk 1 of 3\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.769 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.141 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 2 of 3\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.557 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 4090 spikes in chunk 2 of 3\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.358 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.030 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 3 of 3\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 3.189 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 48825 spikes in chunk 3 of 3\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 1.246 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.358 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.031 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.000 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 0\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649b8273af734b6abf6c46f9c33d4f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/2137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05db8931d60451a94c796ddd6e863b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/2137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0\n",
      "3 0\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 2.1077333333333335 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 63232\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 0.030 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 11 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 0.000 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.000 seconds ***\n",
      "Extracting 11 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.000 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.014 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 1 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.001 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.000 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [0]\n",
      "*** MS5 Elapsed time for align_templates: 0.000 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.000 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.002 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.001 seconds ***\n",
      "Found 1 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.000 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [0]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.000 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.001 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 0.050 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.000 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 0.024 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.000 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.030 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 1\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 0.020 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 15 spikes in chunk 1 of 1\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.000 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.000 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.000 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 0\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4a9eafdd2d40a4875bbb3465981ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db274db7a3914de9ad32f73831cb7b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0\n",
      "4 0\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 463.488 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 13904640\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 13.646 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 3651 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 0.250 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.000 seconds ***\n",
      "Extracting 3651 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.004 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.015 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 3 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.067 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.016 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [  1   0 -14]\n",
      "*** MS5 Elapsed time for align_templates: 0.004 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.000 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.010 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.030 seconds ***\n",
      "Found 1 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.000 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [1]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.000 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.000 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 14.058 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.000 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 3.339 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.007 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.030 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 1\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 3.080 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 4776 spikes in chunk 1 of 1\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.203 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.042 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.001 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.000 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 0\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4ec93472d84c55b08428dcaca94275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7bbeb7cab840028650befbd62d35c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0\n",
      "5 0\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 2040.0725333333332 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 61202176\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 61.430 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 28455 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 2.480 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.000 seconds ***\n",
      "Extracting 28445 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.040 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.020 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 2 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.599 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.077 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [-10   0]\n",
      "*** MS5 Elapsed time for align_templates: 0.000 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.020 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.021 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.668 seconds ***\n",
      "Found 3 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.081 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [-10 -10   0]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.010 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.000 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 65.476 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.010 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 14.484 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.000 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.030 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 2\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.749 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 19537 spikes in chunk 1 of 2\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.594 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.151 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.010 seconds ***\n",
      "Time chunk 2 of 2\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 8.415 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 29130 spikes in chunk 2 of 2\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 1.059 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.320 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.011 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.000 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 0\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6534e16ba74b418b8db66a36ddf191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6987be7a2e641e5b7f09216d442f9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0\n",
      "6 0\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 3600.128 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 108003840\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 107.013 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 101446 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 5.724 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.009 seconds ***\n",
      "Extracting 101275 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.101 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.031 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 3 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 2.194 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.288 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [-12 -11   2]\n",
      "*** MS5 Elapsed time for align_templates: 0.010 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.060 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.059 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 2.182 seconds ***\n",
      "Found 3 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.274 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [-11 -12   2]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.008 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.000 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 118.035 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.000 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 24.444 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.000 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.040 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.836 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 59087 spikes in chunk 1 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 1.168 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.513 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.040 seconds ***\n",
      "Time chunk 2 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.870 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 66903 spikes in chunk 2 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 1.202 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.555 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.030 seconds ***\n",
      "Time chunk 3 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.749 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 69220 spikes in chunk 3 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 1.279 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.570 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.031 seconds ***\n",
      "Time chunk 4 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 7.799 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 6414 spikes in chunk 4 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.458 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.070 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.020 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 0\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6c9ac4bee84fc79f3b722349dc82bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683530dee2b84a3295cc6cccde2f0e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1\n",
      "6 1\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 3600.128 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 108003840\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 107.860 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 18366 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 1.476 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.000 seconds ***\n",
      "Extracting 18340 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.011 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.030 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 4 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.438 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.034 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [ 0 -3 -3  6]\n",
      "*** MS5 Elapsed time for align_templates: 0.010 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.010 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.020 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.605 seconds ***\n",
      "Found 4 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.040 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [ 6  0 -3 -3]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.000 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.000 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 110.626 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.000 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 25.538 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.004 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.030 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 6.149 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 4189 spikes in chunk 1 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.276 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.070 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 2 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.843 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 7320 spikes in chunk 2 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.287 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.054 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 3 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 6.142 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 4533 spikes in chunk 3 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.308 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.040 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.010 seconds ***\n",
      "Time chunk 4 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 7.764 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 8295 spikes in chunk 4 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.416 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.080 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.010 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.000 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 1\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a4287a67794345a9e9d75213f791b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67edea545bf246149036ba16d6f16009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2\n",
      "6 2\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 3600.128 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 108003840\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 107.969 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 46279 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 2.444 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.000 seconds ***\n",
      "Extracting 46204 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.032 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.034 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 3 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.813 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.103 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [-9 -7  4]\n",
      "*** MS5 Elapsed time for align_templates: 0.015 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.036 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.030 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 1.021 seconds ***\n",
      "Found 3 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.138 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [-7  4 -9]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.000 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.000 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 112.724 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.005 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 25.355 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.003 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.030 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.597 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 12706 spikes in chunk 1 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.413 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.120 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 2 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.628 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 27316 spikes in chunk 2 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.573 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.175 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.020 seconds ***\n",
      "Time chunk 3 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.825 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 11825 spikes in chunk 3 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.373 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.110 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 4 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 7.632 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 10242 spikes in chunk 4 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.449 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.061 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.010 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.000 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 2\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69df66c879604b29a42d9b14e4e42938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad501c13efb44898d4134b362511fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3\n",
      "6 3\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 3600.128 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 108003840\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 107.276 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 27181 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 1.615 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.000 seconds ***\n",
      "Extracting 27165 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.017 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.030 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 3 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.646 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.071 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [-9 -7  3]\n",
      "*** MS5 Elapsed time for align_templates: 0.000 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.020 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.021 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 0.201 seconds ***\n",
      "Found 1 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.075 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [3]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.000 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.000 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.000 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 110.033 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.000 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 25.623 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.006 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.039 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 6.071 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 2600 spikes in chunk 1 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.285 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.020 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 2 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.896 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 4595 spikes in chunk 2 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.296 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.040 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 3 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 6.101 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 11344 spikes in chunk 3 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.382 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.111 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Time chunk 4 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 7.837 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 15913 spikes in chunk 4 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.528 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.142 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.000 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.000 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 3\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6e26d4486845eea66b8ae5d7c0a675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e437c979cd9646f6a00d8863633c89b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 4\n",
      "6 4\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 3600.128 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 108003840\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 106.563 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 293305 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 5.273 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.003 seconds ***\n",
      "Extracting 293303 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.285 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.081 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 222 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 184.288 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.893 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [-4 -3 -4 -2  0 -2  0 -4  0  0  0  0  0  0  0 -3 -3  0  0  0 -1  0  0  0\n",
      " -2  1  0 -3 -2 -2 -2 -4 -3 -4 -3 -4 -4 -2 -4 -4 -4 -5 -4  0  0  0 -1 -2\n",
      "  0 -2  3  6  5  4  6  5  4  5  5  4  7  6  6  2  0  0  0  0  0 -2 -3 -4\n",
      " -4 -4 -4 -5 -2 -2 -4 -4 -3 -3 -2 -1 -3 -3 -3 -3 -4 -3 -3 -2 -2 -2  1 -1\n",
      "  0 -1  0 -2 -2 -3 -3 -3  0  3  2  2  1  1  2  2  4  2  3  5  5  1  2  2\n",
      "  2  2  1  2  1  0  4  0  0  0  0  0  0  6  5  4  5  5  5  6  5  5  5  5\n",
      "  6  6  6  4  3  3  8  7  8  0  0  1  2  1  1  2  1  1  1  2  2  2  2  1\n",
      "  3 -2 -7  5  4  5  4  5  5  5  5  5  5  5  5  5  5  5  5  4  6  7  7  6\n",
      "  1 -8 -9 -9 -9 -9 -9 -9 -8 -8 -9 -8 -8 -8 -8 -7 -8 -8 -8 -8 -9  2  0  0\n",
      "  1  5  0 -5  0 -8]\n",
      "*** MS5 Elapsed time for align_templates: 23.566 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.270 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.070 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 195.162 seconds ***\n",
      "Found 220 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.989 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [-4  5 -4 -2  0  4  5 -2  4  0 -2  0 -2 -1 -2  0 -2 -2  0  0  0 -2 -2 -1\n",
      " -1  0 -3 -2 -7 -1 -4 -4 -4  3  1  5  1  5  1  5  0  1  1  0  0  5  4  6\n",
      "  2  2  0  2  0  2  0  0  2  0  5  0  5  0  5  0  0  0  4  4  6  0  6 -4\n",
      "  5  0  0  0  0  6  0  0  0  0  0  2 -4  0  0 -2  0  0  0  0  5  0 -3  3\n",
      "  0  4  6  6  1  1  1  1  1  1  5  1  7  5  5  5  5  5  5  5  5  5  5  1\n",
      "  3  3  5  5  2  6  2 -4 -3 -3 -3 -5  4  4  5  2  8  6  6  4  8  7 -9 -8\n",
      " -7 -7 -8 -8 -8 -9 -9 -9 -7 -8 -9 -8 -8 -9 -4 -4 -4 -4 -3  1 -3 -4 -4 -4\n",
      "  1  3  1  5  7  3  4 -2 -2 -2 -3 -4  8 -2 -3 -1 -3 -2 -3 -3 -2 -4 -4 -4\n",
      " -2 -2 -8 -3 -3 -8 -8 -3 -3 -8 -3 -8 -3  2  2  2  2  2  2  2  2  0  5  0\n",
      "  0  0 -8 -5]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.021 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.010 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.010 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.060 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 517.604 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.097 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 113.312 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.000 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.262 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 23.370 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 90113 spikes in chunk 1 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.893 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.865 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.062 seconds ***\n",
      "Time chunk 2 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 24.523 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 79911 spikes in chunk 2 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.889 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.822 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.036 seconds ***\n",
      "Time chunk 3 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 24.029 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 75254 spikes in chunk 3 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.768 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.668 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.040 seconds ***\n",
      "Time chunk 4 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 12.474 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 74803 spikes in chunk 4 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.769 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.738 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.040 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.040 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 4\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e86be1e1dd44aa3b1bc1afce5ea7e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7e0af7af194817bad2edb26817c2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 5\n",
      "6 5\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 3600.128 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 108003840\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 108.456 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 198725 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 3.243 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.010 seconds ***\n",
      "Extracting 198725 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.191 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.048 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 177 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 83.595 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.538 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [ -1  -2  -3  -3  -4  -4  -4  -5  -3  -2  -2  -3  -3  -3  -3  -2  -4  -4\n",
      "  -4  -4  -4  -3  -3  -5  -5  -5  -6  -6  -4  -2  -4  -5  -5  -5  -4  -2\n",
      "  -3   0   0  -2  -2  -2  -4  -3   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  -3   1   0   1   1   1   1   1   0   1   2\n",
      "   1   1   1   0   0   0   0   0   0   1   3   4   3   4   4   4   4   4\n",
      "   5   5   4   4   5   5   4   5   5   5   3   4   3   2   3   3   4   4\n",
      "   4   4   4   4   4   4   4   4   3   3   3   2   3   3   6   6   5   4\n",
      "   4   5   0  -1   0  -1  -1  -1  -2  -2   5   4   2  -3  11  10   6  11\n",
      "   0   0  -4   0   0   0   0   0   0   0   0   0   1   0   0   0   0  -9\n",
      "  -2 -10  -9 -10  -9  -9  -9  -8  -9  -8   4  -4  -4  -4  -8]\n",
      "*** MS5 Elapsed time for align_templates: 13.247 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.141 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.067 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 97.332 seconds ***\n",
      "Found 179 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.535 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [  0   0   4   0   0   4   4   4   5   5   5   5   5   5   0   1   1   0\n",
      "   1   1   0   1   1   1   1   1   1   5   0   2   1   0   0   1  -5  -4\n",
      "   0   0   0   0   0  -3   4   3   5   3   3   3   2   4   4   4   4  -2\n",
      "   0   4   0  -3  -1  -2  -1   3  -2  -2  -1  -2  -1  -4  -2  -3  -3  -3\n",
      "  -4  -3  -3  -4   0   0  -3  -2  -2  -2  -5  -3  -8  -3  -3  -8  -3   0\n",
      "   0   0   4   4   4   6   0   0   4   4   0   0   0   0   0   4   4   4\n",
      "   4   0   0   0   0   0   0   0   0   0   5   0   0   2   0   0  -6  -5\n",
      "  -4  -4   3   5   3  -6   3   3   3   3   3   3   2   4   1   1 -10  -9\n",
      "  -4  -9  -4  -4  -4  -4  -4  -3  -5  -5  -5 -10 -10  -9  -9  -9  -9  -9\n",
      "  -5  -1  11  10   4  -3   4   0   0   0   0   0   0  -4   1  -8  -8]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.020 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.000 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.041 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.050 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 307.567 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.048 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 31.413 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.000 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.171 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 6.020 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 58340 spikes in chunk 1 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.762 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.508 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.037 seconds ***\n",
      "Time chunk 2 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.771 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 51922 spikes in chunk 2 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.589 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.388 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.030 seconds ***\n",
      "Time chunk 3 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.773 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 51687 spikes in chunk 3 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.570 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.404 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.041 seconds ***\n",
      "Time chunk 4 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 7.621 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 54491 spikes in chunk 4 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.651 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.477 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.030 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.020 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 5\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cb2341c00d41c581a0e5a56f010252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee192801976476c807ecbf47c4877ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "6 6\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 3600.128 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 108003840\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 105.986 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 239496 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 4.195 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.002 seconds ***\n",
      "Extracting 239496 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.227 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.060 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "Found 234 clusters\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 140.434 seconds ***\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.682 seconds ***\n",
      "Determining optimal alignment of templates\n",
      "Template alignment converged.\n",
      "Align templates offsets:  [ 0  0  0  0  0 -1  0  0 -2 -2  0  0  0  0  0  0  0  0  0 -2  0  0  2  1\n",
      "  0  3 -3 -3 -2 -1 -2 -3  0  0  0 -5  0  0  0  2  0 -3 -4 -4 -4 -4 -4 -5\n",
      " -5 -4 -5 -5 -5 -5 -5 -5 -5 -4 -5 -2 -4 -4 -3 -3 -3 -3 -4 -4 -3 -3 -2 -2\n",
      " -4 -2 -2 -3 -3 -4 -4 -4 -3 -4 -3 -3 -3 -4 -4 -4 -5 -4  0  0  0  0  0  0\n",
      "  0 -4  1  1  1  2  2  1  2  2  1  2  1  1  1  0  4  3  3  2  4  3  3  3\n",
      "  3  3  5  5  5  5  5  6  6  6  6  5  5  5  6  6  7  6  5  5  6  5  4  5\n",
      "  4  4  7  7  7  7  5  6  6  7  6  3  4  3  3  4  5  4  5  4  4  4  4  4\n",
      "  5  5  5  5  5  5  4  0 -3 -3 -3 -8 -8 -8  0  1  2  2 -3 -2 -1 -1 -2 -1\n",
      " -1 -3  0 -8 -9 -3 -8 -3 -3 -3 -2 -3  0  0 -2 -2  1  1  1  1  1  1  2  1\n",
      "  1  1  1  3 -8 -9 -9 -9 -8 -9  4  0  3 -7 -5 -3 -1  1]\n",
      "*** MS5 Elapsed time for align_templates: 26.865 seconds ***\n",
      "Aligning snippets\n",
      "*** MS5 Elapsed time for align_snippets: 0.184 seconds ***\n",
      "Clustering aligned snippets\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.066 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n",
      "*** MS5 Elapsed time for isosplit6_subdivision_method: 146.777 seconds ***\n",
      "Found 233 clusters after alignment\n",
      "Computing templates\n",
      "*** MS5 Elapsed time for compute_templates: 0.732 seconds ***\n",
      "Offsetting times to peak\n",
      "Offsets to peak: [ 6  2  0  0  0  0  1  1  5  1  6  5  0  1  5  0  0  5  5  3  6  1  5  0\n",
      "  0  2  6  1  5  0  5  0  3  3  3 -4  0  4  5 -2 -2 -1 -2 -1 -3 -3  0  0\n",
      "  4 -2  5  5  5  4  0 -3 -1  0  5 -2 -2  1  0 -5  0  0  2  0  2 -4 -4 -3\n",
      " -4 -1  3 -2  6 -4 -3 -3 -3 -3 -3 -8 -3 -3 -8 -8 -3 -3 -3 -4 -3 -3 -2 -2\n",
      "  2 -4 -3 -1 -2 -2 -2  4  5 -2 -3 -4 -3 -3 -3 -2  0 -4 -4  2  2 -1  2  2\n",
      " -4  4  4  4  4  4  6  6  6 -5 -5 -5 -9 -8 -5 -5 -5  4 -4 -5  0  0  0 -3\n",
      " -2  0 -3 -8 -9 -9 -9 -8 -9 -9  1  5  5  5  1  1  1  5  5  5  1  1  1  1\n",
      "  1  1  6  6  6  0  0  0  0  2  0  0  0  0 -5 -5  2  5  5  5  0  0 -4 -4\n",
      " -3 -4  0 -4 -5 -5 -5  7  7  7  3  1  7  1  3  1  3 -3 -4 -4  0 -5  3  1\n",
      "  0  0 -7 -5 -5 -3  0  4  3  3  3  0 -2  1  1  1 -1]\n",
      "*** MS5 Elapsed time for determine_offsets_to_peak: 0.030 seconds ***\n",
      "Sorting times\n",
      "*** MS5 Elapsed time for sorting times: 0.000 seconds ***\n",
      "Removing out of bounds times\n",
      "*** MS5 Elapsed time for removing out of bounds times: 0.000 seconds ***\n",
      "Reordering units\n",
      "*** MS5 Elapsed time for reordering units: 0.030 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for creating sorting object: 0.060 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 sorting_scheme1: 426.394 seconds ***\n",
      "*** MS5 Elapsed time for SCHEME2 get_times_labels_from_sorting: 0.097 seconds ***\n",
      "Loading training traces\n",
      "*** MS5 Elapsed time for SCHEME2 training_recording.get_traces: 55.424 seconds ***\n",
      "Training classifier\n",
      "*** MS5 Elapsed time for SCHEME2 training classifier step 1: 0.010 seconds ***\n",
      "Adding snippets from phase 1 sorting\n",
      "Fitting models\n",
      "*** MS5 Elapsed time for SCHEME2 fitting models: 0.292 seconds ***\n",
      "Chunk size: 833.3333333333334 sec\n",
      "Time chunk 1 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.705 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 34742 spikes in chunk 1 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.462 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.316 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.040 seconds ***\n",
      "Time chunk 2 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.847 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 60829 spikes in chunk 2 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.617 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.423 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.030 seconds ***\n",
      "Time chunk 3 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 5.520 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 63483 spikes in chunk 3 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 0.703 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.529 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.031 seconds ***\n",
      "Time chunk 4 of 4\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for SCHEME2 loading traces: 7.582 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 50\n",
      "[[0], [1], [2], [3]]\n",
      "\n",
      "Scheme 2 detected 99566 spikes in chunk 4 of 4\n",
      "*** MS5 Elapsed time for SCHEME2 detecting spikes: 1.213 seconds ***\n",
      "Extracting and classifying snippets\n",
      "*** MS5 Elapsed time for SCHEME2 extracting and classifying snippets: 0.911 seconds ***\n",
      "Updating events\n",
      "Removing duplicates\n",
      "*** MS5 Elapsed time for SCHEME2 updating events: 0.058 seconds ***\n",
      "Concatenating results\n",
      "*** MS5 Elapsed time for SCHEME2 concatenating results: 0.000 seconds ***\n",
      "Perorming label mapping\n",
      "*** MS5 Elapsed time for SCHEME2 label mapping: 0.000 seconds ***\n",
      "Creating sorting object\n",
      "*** MS5 Elapsed time for SCHEME2 creating sorting object: 0.042 seconds ***\n",
      "non-zero-clusters\n",
      "Processing: chronic_2nd_lko_day5_13march_2024_240313_124730, Type: LKO, Recording Index: 6\n",
      "Processing chronic_2nd_lko_day5_13march_2024_240313_124730 at index 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garim\\AppData\\Local\\Temp\\ipykernel_68576\\2406407112.py:195: DeprecationWarning: load_if_exists=True/false is deprcated. Use load_waveforms() instead.\n",
      "  we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d320bddd0bbc44bd82b3963d9dd89866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract waveforms memmap multi buffer:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28dd387cc304da58d97bf3f0ae3d4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract amplitudes:   0%|          | 0/3601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 7\n",
      "6 7\n",
      "[0 1 3 2]\n",
      "Using the full recording for training: 3600.128 sec\n",
      "Running phase 1 sorting\n",
      "Number of channels: 4\n",
      "Number of timepoints: 108003840\n",
      "Sampling frequency: 30000.0 Hz\n",
      "Channel 0: [0. 0.]\n",
      "Channel 1: [ 75. -75.]\n",
      "Channel 2: [150.   0.]\n",
      "Channel 3: [75. 80.]\n",
      "Loading traces\n",
      "*** MS5 Elapsed time for load_traces: 107.658 seconds ***\n",
      "Detecting spikes\n",
      "\n",
      "Adjacency for detect spikes with channel radius 150\n",
      "[[0, 1, 2, 3], [0, 1, 2], [0, 1, 2, 3], [0, 2, 3]]\n",
      "\n",
      "m = 0 (nbhd size: 4)\n",
      "m = 1 (nbhd size: 3)\n",
      "m = 2 (nbhd size: 4)\n",
      "m = 3 (nbhd size: 3)\n",
      "Detected 260462 spikes\n",
      "*** MS5 Elapsed time for detect_spikes: 5.086 seconds ***\n",
      "Removing duplicate times\n",
      "*** MS5 Elapsed time for remove_duplicate_times: 0.006 seconds ***\n",
      "Extracting 260460 snippets\n",
      "*** MS5 Elapsed time for extract_snippets: 0.333 seconds ***\n",
      "Computing PCA features with npca=12\n",
      "*** MS5 Elapsed time for compute_pca_features: 0.089 seconds ***\n",
      "Isosplit6 clustering with npca_per_subdivision=10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.full as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.widgets as sw\n",
    "import probeinterface as pi\n",
    "from probeinterface import Probe, ProbeGroup\n",
    "from probeinterface.plotting import plot_probe, plot_probe_group\n",
    "from probeinterface import generate_multi_columns_probe\n",
    "import pyintan\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "from pathlib import Path\n",
    "import random \n",
    "import pandas as pd\n",
    "import mountainsort5 as ms5\n",
    "all_rec_lists = []\n",
    "all_names = []\n",
    "all_chan = []\n",
    "all_type = []\n",
    "\n",
    "main_folder = Path(r\"E:\\Animal_recordings_all\\depth_4ch\\LKO_depth_4ch\\LKO_Chronic\\LKO_chronic_3\")\n",
    "subfolders = [f.path for f in os.scandir(main_folder) if f.is_dir()]\n",
    "\n",
    "hours_needed = 20\n",
    "minutes_per_hour = 60\n",
    "total_minutes_needed = hours_needed * minutes_per_hour\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    #print(f\"\\nContents of {subfolder}:\")\n",
    "    \n",
    "    list_of_files = os.listdir(subfolder)\n",
    "    list_of_files = [file for file in list_of_files if 'merged' not in file]\n",
    "    list_of_files = [file for file in list_of_files if 'settings' not in file]\n",
    "    error_files = []\n",
    "    print(len(list_of_files))\n",
    "    \n",
    "    total_minutes_collected = 0\n",
    "    subfolder_rec_list = []\n",
    "\n",
    "    while total_minutes_collected < total_minutes_needed and len(list_of_files) > 0:\n",
    "        remaining_minutes_needed = total_minutes_needed - total_minutes_collected\n",
    "        list_of_files_subset = list_of_files[:min(remaining_minutes_needed, 60)]\n",
    "        \n",
    "        #print(f\"Processing these files: {list_of_files_subset}\")\n",
    "        \n",
    "        list_of_recordings = []\n",
    "        for file_name in list_of_files_subset:\n",
    "            file_path = os.path.join(subfolder, file_name)\n",
    "            try:\n",
    "                recording = se.read_intan(file_path, stream_name='RHD2000 amplifier channel', use_names_as_ids=True)  # Assuming data is float32\n",
    "                list_of_recordings.append(recording)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_name}: {e}\")\n",
    "                error_files.append(file_name)\n",
    "                continue\n",
    "\n",
    "        if len(list_of_recordings) > 0:\n",
    "            try:\n",
    "                concatenated_recording = si.concatenate_recordings(list_of_recordings)\n",
    "                rec_cmr = spre.common_reference(concatenated_recording, operator=\"median\", reference=\"global\")  # Rereferencing the data\n",
    "                recording_notch_ecog = spre.notch_filter(rec_cmr, q=50)  # Notch filter\n",
    "                recording_bp = spre.bandpass_filter(recording_notch_ecog, freq_min=300, freq_max=6000)  # Bandpass filter\n",
    "                recording_resampled_ecog = recording_bp\n",
    "\n",
    "                subfolder_rec_list.append(recording_resampled_ecog)\n",
    "                \n",
    "                channel_ids = recording_resampled_ecog.get_channel_ids()\n",
    "                fs = recording_resampled_ecog.get_sampling_frequency()\n",
    "                num_chan = recording_resampled_ecog.get_num_channels()\n",
    "                num_segments = recording_resampled_ecog.get_num_segments()\n",
    "                \n",
    "                #print(\"Channel_ids =\", channel_ids)\n",
    "                #print(f\"Sampling_frequency = {fs}\")\n",
    "                #print(\"Number of Channels =\", num_chan)\n",
    "                #print(\"Number of segments =\", num_segments)\n",
    "               # print('Total_rec_duration =', recording_resampled_ecog.get_total_duration())\n",
    "\n",
    "                k = subfolder.split(\"/\")[-1]\n",
    "                name = k.split(\"\\\\\")[-1]\n",
    "\n",
    "                \n",
    "                all_chan.append(num_chan)\n",
    "\n",
    "                if re.search(r'lko|LKO|L', name):\n",
    "                    type = 'LKO'\n",
    "                    print(f\"Type: {type}\")\n",
    "                else:\n",
    "                    type = 'WT'\n",
    "                    print(\"Type: Not matched\")\n",
    "                \n",
    "                all_type.append(type)\n",
    "                \n",
    "                total_minutes_collected += len(list_of_recordings)\n",
    "\n",
    "            except ValueError as ve:\n",
    "                print(f\"Concatenation error in folder {subfolder}: {ve}\")\n",
    "                continue\n",
    "\n",
    "        list_of_files = list_of_files[len(list_of_files_subset):]\n",
    "    all_names.append(name)\n",
    "    if total_minutes_collected >= total_minutes_needed:\n",
    "        G=1\n",
    "        #print(f\"Successfully created {hours_needed} hours of recordings.\")\n",
    "    else:\n",
    "        F=1\n",
    "        #print(f\"Collected {total_minutes_collected} minutes of recordings.\")\n",
    "    \n",
    "    \n",
    "    all_rec_lists.append(subfolder_rec_list)\n",
    "\n",
    "print(f\"Error files: {error_files}\")\n",
    "\n",
    "\n",
    "hour = ['first_60', 'second_60', 'third_60', 'fourth_60', 'fifth_60', 'sixth_60', 'seventh_60', 'eighth_60', 'ninth_60', 'tenth_60', 'eleventh_60', 'twelfth_60', 'thirteenth_60', 'fourteenth_60', 'fifteenth_60', 'sixteenth_60', 'seventeenth_60', 'eighteenth_60', 'nineteenth_60', 'twentieth_60']\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "g = 1\n",
    "all_sorting=[]\n",
    "for i in range(len(all_rec_lists)):\n",
    "     for j in range(len(all_rec_lists[i])):\n",
    "        print(i,j)\n",
    "        ch = all_rec_lists[i][j].get_num_channels()\n",
    "        print(i, j)\n",
    "        if ch >= 4:\n",
    "            sliced_ch = all_rec_lists[i][j].get_channel_ids()\n",
    "            sliced_ch = sliced_ch[:4]\n",
    "            #sliced_ch = sliced_ch[4:9]\n",
    "            all_rec_lists[i][j] = all_rec_lists[i][j].channel_slice(sliced_ch)\n",
    "            \n",
    "            #if ch == 4:\n",
    "            ch = all_rec_lists[i][j].get_num_channels()\n",
    "            dur = all_rec_lists[i][j].get_total_duration()\n",
    "            \n",
    "           \n",
    "            kk = all_rec_lists[i][j]\n",
    "            #kk = se.read_intan(kk, stream_name='RHD2000 amplifier channel', use_names_as_ids=True)\n",
    "            recording_resampled_ecog = kk\n",
    "           \n",
    "            probe = generate_multi_columns_probe(num_columns=3,\n",
    "                             num_contact_per_column=[1, 2, 1],\n",
    "                             xpitch=75, ypitch=155, y_shift_per_column=[0, -75, 0],\n",
    "                             contact_shapes='square', contact_shape_params={'width' : 20 , 'height' :20 })\n",
    "\n",
    "            channel_indices = np.array([0, 1, 3, 2])\n",
    "            probe.set_device_channel_indices(channel_indices)\n",
    "            print(probe.device_channel_indices)\n",
    "            \n",
    "            contact_ids = np.array([0, 1, 3, 2]) \n",
    "            probe.set_contact_ids(contact_ids)\n",
    "            rec_normed = spre.zscore(recording=recording_resampled_ecog)\n",
    "            rec_2 = spre.whiten(rec_normed) \n",
    "\n",
    "\n",
    "            rec_2.set_probe(probe, in_place = True)\n",
    "            rec_2.get_channel_locations()\n",
    "            #plot_probe(probe, with_contact_id=True, with_device_index=True)\n",
    "                    \n",
    "                        \n",
    "                  \n",
    "            sorting_rec = ms5.sorting_scheme2(rec_2,\n",
    "                sorting_parameters=ms5.Scheme2SortingParameters(\n",
    "                    phase1_detect_channel_radius=150,\n",
    "                    detect_channel_radius=50))        \n",
    "            \n",
    "            all_sorting.append(sorting_rec)\n",
    "            \n",
    "            #print(\"Sorter found\", len(sorting_rec.get_unit_ids()), \"units\")\n",
    "            sorting_rec = sorting_rec.remove_empty_units()\n",
    "            #print(\"Sorter found\", len(sorting_rec.get_unit_ids()), \"non empty units\")\n",
    "            \n",
    "            recording_resampled_ecog.annotate(is_filtered=True) # since we filtered the rec \n",
    "    \n",
    "            if len(sorting_rec.get_unit_ids()) >0 :\n",
    "                print(\"non-zero-clusters\")\n",
    "                \n",
    "                print(f\"Processing: {name}, Type: {type}, Recording Index: {j}\")\n",
    "\n",
    "                waveform_folder = Path(r\"E:\\Animal_recordings_all\\depth_4ch\\LKO_depth_4ch\\LKO_Chronic\\LKO_chronic_1\")\n",
    "                waveform_folder = waveform_folder / f\"waveforms_kshtj_{all_names[i]}_{hour[j]}\" \n",
    "            \n",
    "                waveform_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                type = all_type[i]  \n",
    "                print(f\"Processing {name} at index {i}\")\n",
    "\n",
    "                we = si.extract_waveforms(rec_2, sorting_rec, folder=waveform_folder, load_if_exists=False, overwrite=True,sparse=False) \n",
    "                spost.compute_spike_amplitudes(we)\n",
    "            \n",
    "                unit_ids = sorting_rec.unit_ids\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                #sw.plot_unit_templates(we, unit_ids=unit_ids)\n",
    "                plt.suptitle(f\"{all_names[i]}_{hour[j]}\", fontsize=12, y=0.01)\n",
    "                plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "                plots_directory =  Path(r\"E:\\Animal_recordings_all\\depth_4ch\\LKO_depth_4ch\\LKO_Chronic\\LKO_chronic_1\")\n",
    "                plots_directory.mkdir(parents=True, exist_ok=True) \n",
    "                plt.savefig(plots_directory / f\"{all_names[i]}_{hour[j]}_xx.png\", bbox_inches='tight')\n",
    "               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde06d3-b2c6-4020-adea-c2aabb98a2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
